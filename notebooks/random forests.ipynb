{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "important-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max.rows',200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-nudist",
   "metadata": {},
   "source": [
    "## Train & Evaluate Model in US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-aurora",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriental-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/processed/us-train.csv')\n",
    "val = pd.read_csv('../data/processed/us-val.csv')\n",
    "us = pd.read_csv('../data/processed/us-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sweet-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.log_price\n",
    "y_val = val.log_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emotional-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['log_price'])\n",
    "X_val = val.drop(columns=['log_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_mean = X_train.copy().mean()\n",
    "# X_train_stdev = X_train.copy().std()\n",
    "\n",
    "# # standardize data\n",
    "# X_train = (X_train - X_train_mean)/X_train_stdev\n",
    "# X_val = (X_val - X_train_mean)/X_train_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.fillna(0, inplace=True)\n",
    "# X_train.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# X_val.fillna(0, inplace=True)\n",
    "# X_val.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-locking",
   "metadata": {},
   "source": [
    "### Train Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-biography",
   "metadata": {},
   "source": [
    "### Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forbidden-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unsigned-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statistical-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "acc_train = rf.score(X_train, y_train)\n",
    "acc = rf.score(X_val, y_val)\n",
    "\n",
    "rmse_train = mean_squared_error(np.exp(y_train), np.exp(y_pred_train), squared=False)\n",
    "rmse = mean_squared_error(np.exp(y_val), np.exp(y_pred), squared=False)\n",
    "\n",
    "mae_train = mean_absolute_error(np.exp(y_train), np.exp(y_pred_train))\n",
    "mae = mean_absolute_error(np.exp(y_val), np.exp(y_pred))\n",
    "\n",
    "medae_train = median_absolute_error(np.exp(y_train), np.exp(y_pred_train))\n",
    "medae = median_absolute_error(np.exp(y_val), np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "settled-developer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 (Train): 0.95\n",
      "R^2 (Val): 0.67\n",
      "\n",
      "RMSE (Train): 59.11\n",
      "RMSE (Val): 116.66\n",
      "\n",
      "Mean Abs Error (Train): 21.97\n",
      "Mean Abs Error (Val): 52.53\n",
      "\n",
      "Median Absolute Error (Train): 8.71\n",
      "Median Absolute Error (Val): 24.43\n"
     ]
    }
   ],
   "source": [
    "print('R^2 (Train):', round(acc_train,2)) \n",
    "print('R^2 (Val):', round(acc,2))\n",
    "print('')\n",
    "print('RMSE (Train):', round(rmse_train,2))\n",
    "print('RMSE (Val):', round(rmse,2))\n",
    "print('')\n",
    "print('Mean Abs Error (Train):', round(mae_train,2))\n",
    "print('Mean Abs Error (Val):', round(mae,2))\n",
    "print('')\n",
    "print('Median Absolute Error (Train):', round(medae_train,2))\n",
    "print('Median Absolute Error (Val):', round(medae,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-windows",
   "metadata": {},
   "source": [
    "### Random Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf parameters input into random search\n",
    "n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# produce random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search best hyper parameters of model\n",
    "rf_r = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf_r, param_distributions = random_grid, n_iter = 15, cv = 5, \n",
    "                               verbose=2, random_state=0, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the random search model on 3 cross validations with 20 iters each\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best random search parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artificial-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt = RandomForestRegressor(n_estimators=100, min_samples_split=2, \n",
    "                                min_samples_leaf=2, max_features='auto',\n",
    "                               max_depth=15, bootstrap=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "theoretical-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf_opt.predict(X_train)\n",
    "y_pred = rf_opt.predict(X_val)\n",
    "\n",
    "acc_train = rf.score(X_train, y_train)\n",
    "acc = rf.score(X_val, y_val)\n",
    "\n",
    "rmse_train = mean_squared_error(np.exp(y_train), np.exp(y_pred_train), squared=False)\n",
    "rmse = mean_squared_error(np.exp(y_val), np.exp(y_pred), squared=False)\n",
    "\n",
    "mae_train = mean_absolute_error(np.exp(y_train), np.exp(y_pred_train))\n",
    "mae = mean_absolute_error(np.exp(y_val), np.exp(y_pred))\n",
    "\n",
    "medae_train = median_absolute_error(np.exp(y_train), np.exp(y_pred_train))\n",
    "medae = median_absolute_error(np.exp(y_val), np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "above-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 (Train): 0.95\n",
      "R^2 (Val): 0.67\n",
      "\n",
      "RMSE (Train): 82.39\n",
      "RMSE (Val): 117.44\n",
      "\n",
      "Mean Abs Error (Train): 36.86\n",
      "Mean Abs Error (Val): 53.22\n",
      "\n",
      "Median Absolute Error (Train): 18.28\n",
      "Median Absolute Error (Val): 24.95\n"
     ]
    }
   ],
   "source": [
    "print('R^2 (Train):', round(acc_train,2)) \n",
    "print('R^2 (Val):', round(acc,2))\n",
    "print('')\n",
    "print('RMSE (Train):', round(rmse_train,2))\n",
    "print('RMSE (Val):', round(rmse,2))\n",
    "print('')\n",
    "print('Mean Abs Error (Train):', round(mae_train,2))\n",
    "print('Mean Abs Error (Val):', round(mae,2))\n",
    "print('')\n",
    "print('Median Absolute Error (Train):', round(medae_train,2))\n",
    "print('Median Absolute Error (Val):', round(medae,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-vector",
   "metadata": {},
   "source": [
    "## Plotting & Interpretting Training & Validation Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "strategic-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_train = y_train - y_pred_train\n",
    "diff_val = y_val - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diff_train, bins=40, label='train')\n",
    "plt.hist(diff_val, bins=40, label='val')\n",
    "plt.title('Distribution of model errors')\n",
    "plt.ylabel('Number of observations')\n",
    "plt.xlabel('Log Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-canvas",
   "metadata": {},
   "source": [
    "## US & International Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collective-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create full train set (val + existing train)\n",
    "X = pd.concat([X_train, X_val]).reset_index(drop=True)\n",
    "y = pd.concat([y_train, y_val]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "willing-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test set\n",
    "y_test = us.log_price\n",
    "X_test = us.drop(columns=['log_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "# X_test = (X_test - X_train_mean)/X_train_stdev\n",
    "# X_test.fillna(0, inplace=True)\n",
    "# X_test.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "phantom-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = RandomForestRegressor(n_estimators=100, min_samples_split=2, \n",
    "                                min_samples_leaf=2, max_features='auto',\n",
    "                               max_depth=15, bootstrap=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "answering-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf_final.predict(X)\n",
    "y_pred = rf_final.predict(X_test)\n",
    "\n",
    "acc_train = rf.score(X, y)\n",
    "acc = rf.score(X_test, y_test)\n",
    "\n",
    "rmse_train = mean_squared_error(np.exp(y), np.exp(y_pred_train), squared=False)\n",
    "rmse = mean_squared_error(np.exp(y_test), np.exp(y_pred), squared=False)\n",
    "\n",
    "mae_train = mean_absolute_error(np.exp(y), np.exp(y_pred_train))\n",
    "mae = mean_absolute_error(np.exp(y_test), np.exp(y_pred))\n",
    "\n",
    "medae_train = median_absolute_error(np.exp(y), np.exp(y_pred_train))\n",
    "medae = median_absolute_error(np.exp(y_test), np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "meaning-scout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 (Train): 0.88\n",
      "R^2 (Test): 0.66\n",
      "\n",
      "RMSE (Train): 83.0\n",
      "RMSE (Test): 119.46\n",
      "\n",
      "Mean Abs Error (Train): 37.66\n",
      "Mean Abs Error (Test): 53.63\n",
      "\n",
      "Median Absolute Error (Train): 18.82\n",
      "Median Absolute Error (Test): 24.94\n"
     ]
    }
   ],
   "source": [
    "print('R^2 (Train):', round(acc_train,2)) \n",
    "print('R^2 (Test):', round(acc,2))\n",
    "print('')\n",
    "print('RMSE (Train):', round(rmse_train,2))\n",
    "print('RMSE (Test):', round(rmse,2))\n",
    "print('')\n",
    "print('Mean Abs Error (Train):', round(mae_train,2))\n",
    "print('Mean Abs Error (Test):', round(mae,2))\n",
    "print('')\n",
    "print('Median Absolute Error (Train):', round(medae_train,2))\n",
    "print('Median Absolute Error (Test):', round(medae,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test, bins=40, label='actual')\n",
    "plt.hist(y_pred, bins=40, label='predictions')\n",
    "plt.title('Distribution of model errors')\n",
    "plt.ylabel('Number of observations')\n",
    "plt.xlabel('Log Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_train = y - y_pred_train\n",
    "diff_test = y_test - y_pred\n",
    "\n",
    "plt.hist(diff_train, bins=40, label='train')\n",
    "plt.hist(diff_val, bins=40, label='test')\n",
    "plt.title('Distribution of model errors')\n",
    "plt.ylabel('Number of observations')\n",
    "plt.xlabel('Log Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-century",
   "metadata": {},
   "source": [
    "## Import international data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "competitive-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid = pd.read_csv('../data/processed/madrid_test.csv')\n",
    "london = pd.read_csv('../data/processed/london_test.csv')\n",
    "paris = pd.read_csv('../data/processed/paris_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "administrative-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_y = madrid.log_price\n",
    "madrid_X = madrid.drop(columns=['log_price', 'price'])\n",
    "\n",
    "london_y = london.log_price\n",
    "london_X = london.drop(columns=['log_price', 'price'])\n",
    "\n",
    "paris_y = paris.log_price\n",
    "paris_X = paris.drop(columns=['log_price', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "helpful-comedy",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7f32de16392a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# standardize madrid data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmadrid_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmadrid_X\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_train_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX_train_stdev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmadrid_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmadrid_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_mean' is not defined"
     ]
    }
   ],
   "source": [
    "# standardize madrid data\n",
    "madrid_X = (madrid_X - X_train_mean)/X_train_stdev\n",
    "madrid_X.fillna(0, inplace=True)\n",
    "madrid_X.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# standardize london data\n",
    "london_X = (london_X - X_train_mean)/X_train_stdev\n",
    "london_X.fillna(0, inplace=True)\n",
    "london_X.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# standardize madrid data\n",
    "paris_X = (paris_X - X_train_mean)/X_train_stdev\n",
    "paris_X.fillna(0, inplace=True)\n",
    "paris_X.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-leone",
   "metadata": {},
   "source": [
    "#### Madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "viral-patrick",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7eae465006a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmadrid_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmadrid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmadrid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mids-python/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mids-python/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mids-python/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    390\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mids-python/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mids-python/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 645\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mids-python/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n\u001b[0;32m---> 99\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    100\u001b[0m             )\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "y_pred = rf_final.predict(madrid_X)\n",
    "\n",
    "acc = r2_score(np.exp(madrid_y), np.exp(y_pred))\n",
    "\n",
    "rmse = mean_squared_error(np.exp(madrid_y), np.exp(y_pred), squared=False)\n",
    "\n",
    "mae = mean_absolute_error(np.exp(madrid_y), np.exp(y_pred))\n",
    "\n",
    "medae = median_absolute_error(np.exp(madrid_y), np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2 (Madrid):', round(acc,2))\n",
    "print('')\n",
    "print('RMSE (Madrid):', round(rmse,2))\n",
    "print('')\n",
    "print('Mean Abs Error (Madrid):', round(mae,2))\n",
    "print('')\n",
    "print('Median Absolute Error (Madrid):', round(medae,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-greece",
   "metadata": {},
   "source": [
    "#### London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_final.predict(london_X)\n",
    "\n",
    "acc = r2_score(np.exp(london_y), np.exp(y_pred))\n",
    "\n",
    "rmse = mean_squared_error(np.exp(london_y), np.exp(y_pred), squared=False)\n",
    "\n",
    "mae = mean_absolute_error(np.exp(london_y), np.exp(y_pred))\n",
    "\n",
    "medae = median_absolute_error(np.exp(london_y), np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2 (London):', round(acc,2))\n",
    "print('')\n",
    "print('RMSE (London):', round(rmse,2))\n",
    "print('')\n",
    "print('Mean Abs Error (London):', round(mae,2))\n",
    "print('')\n",
    "print('Median Absolute Error (London):', round(medae,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-debut",
   "metadata": {},
   "source": [
    "#### Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_final.predict(paris_X)\n",
    "\n",
    "acc = r2_score(np.exp(paris_y), np.exp(y_pred))\n",
    "\n",
    "rmse = mean_squared_error(np.exp(paris_y), np.exp(y_pred), squared=False)\n",
    "\n",
    "mae = mean_absolute_error(np.exp(paris_y), np.exp(y_pred))\n",
    "\n",
    "medae = median_absolute_error(np.exp(paris_y), np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2 (Paris):', round(acc,2))\n",
    "print('')\n",
    "print('RMSE (Paris):', round(rmse,2))\n",
    "print('')\n",
    "print('Mean Abs Error (Paris):', round(mae,2))\n",
    "print('')\n",
    "print('Median Absolute Error (Paris):', round(medae,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
